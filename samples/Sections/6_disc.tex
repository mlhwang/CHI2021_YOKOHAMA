
%, particularly with macronutrient assessment based on crowdsourced meal photographs. 
% and found users' confidence assessing macronutrients increased after using the app. Strong player-avatar-identification (PAID) and increased utilization of the crowdsourced community board were related to users' enjoyment of the app. Interestingly, lower PAID predicted greater recall of nutrition information, independent of prior nutrition knowledge. Findings suggest PAID may be an important mechanism in learning and highlights how fun, lightweight tools can prompt reflection and recall.

\vspace{-5pt}
\section{Discussion}

% What are the questions we asked
We piloted Monster Munch (N=68) as a feasibility-focused study to test out two main mechanisms: player avatar relationships and a crowdsourced community board as a resource for decision making in the app. Though avatars are frequently utilized gamified apps and games, there are few instances of them embodying learning content and paired with crowdsourced social features. Beyond understanding the impact on enjoyment of the app that users experienced with these these mechanisms, we wanted to understand the level to which these mechanisms encouraged users to engage with nutrition topics - a notoriously difficult task in the space of nutritional education.

% concisely highlight key findings here - what do these findings mean, what are you about to argue below?
We found that overall our users enjoyed using the app and their self-reported confidence for assessing macronutrient content in meal photographs increased post app-usage.
A key insight was that specifically, identification with the pet monster avatar, as well as engagement with the community board, was highly predictive of enjoyment, rating of the app, and recommending the app to others. 
Learning was only moderately shown with those who did not identify with their avatars highly, showing that further investigation is due for measuring learning outcomes as a by-product of exploring gamification and social mechanisms.  


\vspace{-5pt}
\subsection{Gamification Mechanisms with User Experience and Learning}
Overall, we found positive experiences reported by the users with their pet monster avatars. The Player-Avatar-Identification (PAID) score was a strong predictor of enjoyment, rating, and recommendation of the app to others. In the post-task, we asked users to rate how much they liked using monsters to learn about meals and nutrition and majority of the users expressed \textcolor{red}{report STATS} liking the monster avatars a great deal as a vehicle for delivering meal correctness feedback. In particular, participants who reported having a high school education or less identified significantly more with their avatars, possibly because it is generally more accessible to retrieve nutritional information through visual effects as opposed to text. In addition, we purposefully chose monster avatars with the intention of eliminating additional complexity that can be derived from various aspects such as gender influence. This aspect probably aided in terms of receiving majority positive feedback regarding the pet monster avatars.  

In our study, users were allowed to choose a monster avatar with specific health goals \textcolor{red}{(REALIZED WE DIDN'T LOOK INTO THIS PARTICULAR QUESTION ---Let's write in some ``common'' reasons why people have chose their specific monsters and I think that might help this paragraph.)} and then were allowed to name their pet avatar. It is possible that these features helped the users feel more associated with the characters by taking a form of ``ownership'' of the avatar. Fondness for a character (Cohen, 1999), attractiveness of avatars (Kim, Lee, \& Kang, 2012), the capabilities of the character (Newman, 2002) are some of the features that have been identified in facilitating avatar identification~\cite{turkay2014effects}. Though the interaction time with the pet monster avatar in the app was not very long (AVERAGE TIME SPENT ON APP FOR ALL --- ADD HERE), many users have mentioned how the monster avatars were cute and adorable in the free feedback question regarding the entire study, not even specifically asking the user's perception of the avatars, which supports the positive evaluation towards the avatars. One aspect that was unfortunate of the app was that most users did not become aware of the ``unlocking accessories'' feature, unless they chose the correct meal at least four times in a row. Typically, cosmetic avatar customization can be strongly related to identification~\cite{turkay2014effects}, but our users did not know about the accessories. They did, however, ``controlled'' how the avatars would look by selecting the correct or incorrect meal to feed them. Having more options for avatar customization that users were aware of should be considered in the future. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%% LEARNING %%%%%%%%%%%%%

We were surprised to find that lower PAID scores marginally predicted greater recall of nutrition information at post-test, even after controlling for baseline nutrition knowledge, educational background, and Monster Munch app performance. It is possible that the high identification with the pet monster avatars and the crowdsourced-based community board were excessive inputs and stimuli for our users. One study~\cite{makransky2019adding} showed that placing university students in an immersive virtual science world through VR headsets led them to higher presence in the virtual learning simulation but resulted in poorer learning outcomes and higher cognitive loads. Our users had to process quite a bit of information in each round in the app: visually they had to view the four individual meal options; they had to read the descriptions of those meals and process that information; they had to write a text-based reasoning for their initial choice to feed the pet avatar; they had to then process the information in the community board that included voting and reasoning for all four meal options; and then they had to provide an additional text-based reasoning for their final choice to feed their monsters. Only then they were given correctness feedback of the meal they decided to feed their monster avatar. In addition, while the app always gave four meal options to choose from, the pre- and post-assessment questions were always a choice between two meal options and correctness feedback was never provided, which does complicate the definition of ``recall learning'' that we refer to in this section. Further investigation is necessary to measure specific learning outcomes that may mimic the intervention activities more closely to see if avatar identification emerges as an important possible predictor of nutritional knowledge and literacy.

% It is possible that the correlation we are seeing between higher PAID scores and lower learning scores suggests that the users that related more to their avatars with nutritional goals because they themselves struggle with nutrition? 

% This would suggest that the user would have higher engagement with an extended version of the Monster Munch app, leading to a future increased nutritional learning?

Though not directly related to learning outcomes per se, our study showed that users' self-reported confidence of their ability to assess macronutrients increased after using the app. This shows great potential for photo-based macronutrient nutrition education, as confidence in learning is shown to be correlated to actual learning outcomes ~\cite{badura1995exercise,choi2005self,de2013relationship,nicholson2013key,wesson2011self}. One user mentioned that this app has great potential as an education app (ID NUMBER) and another user said: \textit{``If people care about their nutritional intake, it is a cute [app]! I am a vegetarian so not the biggest fan about seeing many pictures of meat. ''} (shloming ID).
This shows that there is potential to improve the current app to cater meal photos to individual's dietary preferences and restrictions and this could further aid in the app becoming a more effective educational, teaching tool. 

% -- in general, though it was not required, majority wrote a positive response about the study (most were short like , fun, good, awesome, but all still positive and question was not required to input anything)
% \textit{``it seems interesting, best of luck! I would definitely use this app.''} (ID-043845)

These results suggest the affinity between players and their avatars may be a crucial component to the overall positive experience with the app.

We saw that user's self-reported frequency of using the community board's suggestion (to determine what to feed their monster avatar)  significantly predicted their enjoyment, rating, and recommendation of the app. 

Together these findings highlight the importance of user's engagement with gamification and social components to their overall experience using and enjoying the app. 

% Theory of behavior change --- engagement is one of the first steps of this theory
% learning takes a long time so they behavioral change , so we are looking for more active learning , how do you attain sustainment, or engagement, continue users to inquire about nutrition topics, well how do you get that? with ENGAGEMENT


% ``Self Determination Theory (SDT, Deci \&
% Ryan, 1985) posits that autonomy, competence
% and relatedness are necessary for people’s wellbeing, and was used previously to explain motivational aspects of MMOs (Przybylski, Rigby
% \& Ryan, 2010).''~\cite{turkay2014effects}


% `` previous studies determined
% various player behaviors, features of avatars, and
% characteristics of virtual worlds, that facilitate
% identification. Among these features are fondness for a character (Cohen, 1999), attractiveness of avatars (Kim, Lee, & Kang, 2012), the
% capabilities of the character (Newman, 2002),
% point-of-view (Lim & Reeves, 2009), and
% physical resemblance of avatars to their users
% in body shape, race, age, and facial features
% (Maccoby & Wilson, 1957; Williams, 2011).''~\cite{turkay2014effects}


% `` because players chose
% their avatars’ aspects they felt more associated
% with the character by “taking ownership” of
% it.''





\subsection{Limitations and Future Work}

% Limitations of this research study in this particular scope is discussed in the following sections. 

% \textcolor{red}{What about > While we asked ``What do you think of using monster avatars and their nutritional goal as a way of assessing macronutrient content in meal photographs?'' as an open-ended question in the Data Collection Phase, we had decided to reformat the question on a scale for the Pilot Phase (PP) in an attempt to lessen the effort? asked of the participant as the neared the end of the study.} In the DCP responses for this question, we received a few interesting insights: ``I think it is silly, more for kids than adults''; ``It seems like it would attract peoples' attention a little more than the alternative of just discussing nutrition in a totally abstract way.''; ``It creates a personal feeling which may be advantageous to getting better results''; ``It adds a fun and lighthearted aspect to learning about these things.''; ``It's something that i've never seen before, it caught my attention and i believe it will catch The attention of other People too.''; ``Monster avtar is great and it has sharpen my knowledge that which food has more carbs.'' Among the people who contributed to this question (STATS), certain \% was positive. 

% --- even though the negative comment about the app being for kids and silly is from DCP, this may be an explanation why there was a low PAID score with higher educated people. Maybe the perception was that, the monsters were less relateble because it seemed a bit childish for them. 

% \subsubsection{Limitations with the Gamification Mechanisms}

For the ``unlock accessory'' feature, players were not made aware accessories were available to ``upgrade'' one's monster avatar if four and five rounds worth of meals were correctly fed to the avatar. Only those who reached the four and five correct answers in a row discovered the ``unlock accessory'' feature. If the feature was announced to every user from the beginning and that this could be a goal to strive for maybe we would have witnessed longer duration time stamps for the app activities, and more careful choices might have been made. Additionally, there was no final ``winning'' or ``losing'' status mentioned to the players. If we made receiving accessories the ``winning state'' for the users, the app would have felt more like a game and could have fostered more motivation to play longer as well. We were considering an option to add a button to ``play again'' with a different or the same monster and measured their willingness to continue ``playing the game.'' This would be an excellent next phase to measure engagement and enjoyment in more dynamic ways. 

% Given the easy nature of data collection, Amazon Mechanical Turkers (AMTs) were used for the data collection phase and half of the pilot participants were AMTs. We did receive quite a variety of responses with the AMTs, and in particular, when they were asked to provide a text-based reason for their meal choices before the community board (CB) and after CB, it became clear that many were not reading the instructions or did not put much effort into the task. We rejected a number of HITs as those responses were of ``low-quality'' from our research perspective. Whether we rejected and approved the ``right'' responses will be difficult to assess in any capacity. 

% How much can we guarantee that the post-test responses were not influenced by fatigue. (Maybe this is a good place to quickly mention the average duration people took to complete the entire study? -- first mention this in the Evaluation section when maybe talking about Participants)


% \subsubsection{Determining the Gold Standard for ``in-the-wild'' Meal Photographs}
% First of all, we involved quite a number of people to achieve this. But also the meal photographs are from our previous studies~\cite{} -- keep it anonymized-- and that means most meals are from a particular geographical population (Washington Heights). In creating a true ``crowdsourced intelligence'' driven community board we would have to do a much more comprehensive collection of meal photographs. Maybe using soical media sites like IG and TikTok might help?

% Taken from \cite{cuthbert2019effects}:
% ``Secondly, this study had a small number of participants
% which made the statistics very vulnerable to type II errors.
% We tried to deal with this limitation by reporting effect sizes,
% descriptive statistics, and all the p values, avoiding the typical
% practice of sharing only statistically significant results.''


Because this was a pilot study, the true form of what we want to produce is far from what we tested here. In fact, though we would love a full-fledged game (we did not quite make it a game and only tested out a few gamification mechanisms) freely used by the crowd and the content driven by the crowd, in this particular pilot, we had to pre-process a lot of the data ourselves. The meal photographs were from real users of an app developed in our previous work (keep anonymous) but the gold standard for their evaluation were taken from professional dietitians as we needed a starting point. In future iterations of this study, we will use the data collected in our pilot and include the voting and reasoning for meal choices in the community board. In this way the community board will be created, maintained, and updated truly by the crowd's input and opinion.  
%(\textcolor{orange}{why not use the users' evaluations instead? What is our rationale for this? if we wanted a crowdsourced CB in the truest sense, we should have taken the users' assessments. so why?}

For meal options that were clearly not preferred and fitting the nutritional goal of the monster avatar, we had no text-based reasoning/descriptions for why that particular meal would be the ``right'' choice. Therefore, we had to request our users in the Data Collection Phase to assume that those meals were the right meals for the nutritional goal and provide text-based reasoning for why the meals fit a particular nutritional goal. Moving forward meals that completely do not fit a nutritional goal, and therefore, were not voted for by the crowd should be left empty with no text-based reasoning. If it is clearly not the right choice by the crowd, then let that evaluation show in the community board.  
%(\textcolor{orange}{Again, why not use the users' true evaluations instead? As in there were ZERO reasons for a meal to fit a nutritional goal. What is our rationale?}


All APKs and relevant data pre-processing and data extraction scripts are available on our Github for the HCI community (anonymous link here). 



% How do we get to a truly crowdsourced community board that really represents all people and all types of food? Is that even possible? Could there be one place, one repository for this, or should there not be just one repository? How can we do this more at scale?

\textcolor{orange}{This app with gamification and social mechanisms is a platform that has a potential to grow and aggregate many more crowdsourced, ``in-the-wild'' meal photographs that are also evaluated by the crowd. Given that we involved so many experts, and the gold standard for the meals used were also from trained dietitians, and it took us considerable amount of time to filter through the meals, this whole lightweight and ``naturally crowdsourced'' claim may be difficult. So how do we avoid that attack from the reviewers?????????}

Next step is to make this into a full-fledged game, with winning and losing states, have the crowdsourced community add more meal photographs with their evaluations and have them compete against each other so that they have to achieve their health goal faster in a given amount of time. This will add the competitive nature that is popular in many successful games. 

